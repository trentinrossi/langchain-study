{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCvtxtyyCiYG"
      },
      "source": [
        "## Chat Models - <a href='https://python.langchain.com/docs/modules/data_connection/document_loaders/'>Document Loaders</a> and Text Splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ilpML_49CiYI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.3)\n",
            "Requirement already satisfied: langchain_openai in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.0.14)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.14 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.1.14)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.0.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.26.3)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.5.3)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.6.1 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_openai) (0.5.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.2,>=0.1.14->langchain) (4.2.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.2,>=0.1.14->langchain) (23.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (0.26.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken<0.6.0,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\rgri\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai<2.0.0,>=1.6.1->langchain_openai) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rgri\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain langchain_openai beautifulsoup4 --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-CA9pNvCiYJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'API_KEY_HERE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IEvhajVQCiYJ"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "import requests\n",
        "\n",
        "# Get this file and save it locally:\n",
        "url = \"https://github.com/hammer-mt/thumb/blob/master/README.md\"\n",
        "\n",
        "# Save it locally:\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extract the text from the HTML:\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "text = soup.get_text()\n",
        "\n",
        "with open(\"README.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "loader = TextLoader('README.md', encoding=\"utf-8\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='{\"payload\":{\"allShortcutsEnabled\":false,\"fileTree\":{\"\":{\"items\":[{\"name\":\".github\",\"path\":\".github\",\"contentType\":\"directory\"},{\"name\":\"img\",\"path\":\"img\",\"contentType\":\"directory\"},{\"name\":\"notebooks\",\"path\":\"notebooks\",\"contentType\":\"directory\"},{\"name\":\"src\",\"path\":\"src\",\"contentType\":\"directory\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\"CONTRIBUTING.md\",\"path\":\"CONTRIBUTING.md\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"RESOURCES.md\",\"path\":\"RESOURCES.md\",\"contentType\":\"file\"},{\"name\":\"TODO.md\",\"path\":\"TODO.md\",\"contentType\":\"file\"},{\"name\":\"requirements.txt\",\"path\":\"requirements.txt\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"},{\"name\":\"webui.bat\",\"path\":\"webui.bat\",\"contentType\":\"file\"},{\"name\":\"webui.sh\",\"path\":\"webui.sh\",\"contentType\":\"file\"}],\"totalCount\":13}},\"fileTreeProcessingTime\":5.820067,\"foldersToFetch\":[],\"reducedMotionEnabled\":null,\"repo\":{\"id\":684171643,\"defaultBranch\":\"master\",\"name\":\"thumb\",\"ownerLogin\":\"hammer-mt\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2023-08-28T15:48:03.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/5264596?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":false},\"symbolsExpanded\":false,\"treeExpanded\":true,\"refInfo\":{\"name\":\"master\",\"listCacheKey\":\"v0:1702391649.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"8a3d39895b998991c3fc3b95c7cc2bf2a5642f85\"},\"path\":\"README.md\",\"currentUser\":null,\"blob\":{\"rawLines\":null,\"stylingDirectives\":null,\"csv\":null,\"csvError\":null,\"dependabotInfo\":{\"showConfigurationBanner\":false,\"configFilePath\":null,\"networkDependabotPath\":\"/hammer-mt/thumb/network/updates\",\"dismissConfigurationNoticePath\":\"/settings/dismiss-notice/dependabot_configuration_notice\",\"configurationNoticeDismissed\":null,\"repoAlertsPath\":\"/hammer-mt/thumb/security/dependabot\",\"repoSecurityAndAnalysisPath\":\"/hammer-mt/thumb/settings/security_analysis\",\"repoOwnerIsOrg\":false,\"currentUserCanAdminRepo\":false},\"displayName\":\"README.md\",\"displayUrl\":\"https://github.com/hammer-mt/thumb/blob/master/README.md?raw=true\",\"headerInfo\":{\"blobSize\":\"10.8 KB\",\"deleteInfo\":{\"deleteTooltip\":\"You must be signed in to make or propose changes\"},\"editInfo\":{\"editTooltip\":\"You must be signed in to make or propose changes\"},\"ghDesktopPath\":\"https://desktop.github.com\",\"gitLfsPath\":null,\"onBranch\":true,\"shortPath\":\"054a9b9\",\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fhammer-mt%2Fthumb%2Fblob%2Fmaster%2FREADME.md\",\"isCSV\":false,\"isRichtext\":true,\"toc\":[{\"level\":1,\"text\":\"thumb\",\"anchor\":\"thumb\",\"htmlText\":\"thumb\"},{\"level\":2,\"text\":\"Quick start\",\"anchor\":\"quick-start\",\"htmlText\":\"Quick start\"},{\"level\":3,\"text\":\"1. Install the library\",\"anchor\":\"1-install-the-library\",\"htmlText\":\"1. Install the library\"},{\"level\":3,\"text\":\"2. Set up a test\",\"anchor\":\"2-set-up-a-test\",\"htmlText\":\"2. Set up a test\"},{\"level\":3,\"text\":\"3. Rate the responses\",\"anchor\":\"3-rate-the-responses\",\"htmlText\":\"3. Rate the responses\"},{\"level\":2,\"text\":\"Functionality\",\"anchor\":\"functionality\",\"htmlText\":\"Functionality\"},{\"level\":3,\"text\":\"Test cases\",\"anchor\":\"test-cases\",\"htmlText\":\"Test cases\"},{\"level\":3,\"text\":\"Model testing\",\"anchor\":\"model-testing\",\"htmlText\":\"Model testing\"},{\"level\":3,\"text\":\"System messages\",\"anchor\":\"system-messages\",\"htmlText\":\"System messages\"},{\"level\":3,\"text\":\"Evaluation report\",\"anchor\":\"evaluation-report\",\"htmlText\":\"Evaluation report\"},{\"level\":3,\"text\":\"Parameters\",\"anchor\":\"parameters\",\"htmlText\":\"Parameters\"},{\"level\":4,\"text\":\"Required\",\"anchor\":\"required\",\"htmlText\":\"Required\"},{\"level\":4,\"text\":\"Optional\",\"anchor\":\"optional\",\"htmlText\":\"Optional\"},{\"level\":3,\"text\":\"Loading and adding\",\"anchor\":\"loading-and-adding\",\"htmlText\":\"Loading and adding\"},{\"level\":2,\"text\":\"Thumb Testing üëçüß™\",\"anchor\":\"thumb-testing-\",\"htmlText\":\"Thumb Testing üëçüß™\"},{\"level\":2,\"text\":\"Contributors\",\"anchor\":\"contributors\",\"htmlText\":\"Contributors\"}],\"lineInfo\":{\"truncatedLoc\":\"249\",\"truncatedSloc\":\"169\"},\"mode\":\"file\"},\"image\":false,\"isCodeownersFile\":null,\"isPlain\":false,\"isValidLegacyIssueTemplate\":false,\"issueTemplateHelpUrl\":\"https://docs.github.com/articles/about-issue-and-pull-request-templates\",\"issueTemplate\":null,\"discussionTemplate\":null,\"language\":\"Markdown\",\"languageID\":222,\"large\":false,\"loggedIn\":false,\"newDiscussionPath\":\"/hammer-mt/thumb/discussions/new\",\"newIssuePath\":\"/hammer-mt/thumb/issues/new\",\"planSupportInfo\":{\"repoIsFork\":null,\"repoOwnedByCurrentUser\":null,\"requestFullPath\":\"/hammer-mt/thumb/blob/master/README.md\",\"showFreeOrgGatedFeatureMessage\":null,\"showPlanSupportBanner\":null,\"upgradeDataAttributes\":null,\"upgradePath\":null},\"publishBannersInfo\":{\"dismissActionNoticePath\":\"/settings/dismiss-notice/publish_action_from_dockerfile\",\"dismissStackNoticePath\":\"/settings/dismiss-notice/publish_stack_from_file\",\"releasePath\":\"/hammer-mt/thumb/releases/new?marketplace=true\",\"showPublishActionBanner\":false,\"showPublishStackBanner\":false},\"rawBlobUrl\":\"https://github.com/hammer-mt/thumb/raw/master/README.md\",\"renderImageOrRaw\":false,\"richText\":\"thumb\\\\nA simple prompt testing library for LLMs.\\\\nQuick start\\\\n1. Install the library\\\\n\\\\npip install thumb\\\\n\\\\n2. Set up a test\\\\nimport os\\\\nimport thumb\\\\n\\\\n# Set your API key: https://platform.openai.com/account/api-keys\\\\nos.environ[\\\\\"OPENAI_API_KEY\\\\\"] = \\\\\"YOUR_API_KEY_HERE\\\\\"\\\\n\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke\\\\\"\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b])\\\\n3. Rate the responses\\\\nEach prompt is run 10 times asynchronously by default, which is around 9x faster than running them sequentially. In Jupyter Notebooks a simple user interface is displayed for blind rating responses (you don\\'t see which prompt generated the response).\\\\n\\\\nOnce all responses have been rated, the following performance statistics are calculated broken down by prompt template:\\\\n\\\\navg_score amount of positive feedback as a percentage of all runs\\\\navg_tokens: how many tokens were used across the prompt and response\\\\navg_cost: an estimate of how much the prompt cost to run on average\\\\n\\\\nA simple report is displayed in the notebook, and the full data is saved to a CSV file thumb/ThumbTest-{TestID}.csv.\\\\n\\\\nFunctionality\\\\nTest cases\\\\nTest cases are when you want to test a prompt template with different input variables. For example, if you want to test a prompt template that includes a variable for a comedian\\'s name, you can set up test cases for different comedians.\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke in the style of {comedian}\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke in the style of {comedian}\\\\\"\\\\n\\\\n# set test cases with different input variables\\\\ncases = [\\\\n  {\\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n  {\\\\\"comedian\\\\\": \\\\\"ricky gervais\\\\\"}, \\\\n  {\\\\\"comedian\\\\\": \\\\\"robin williams\\\\\"}\\\\n  ]\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], cases)\\\\nEvery test case will be run against every prompt template, so in this example you\\'ll get 6 combinations (3 test cases x 2 prompt templates), which will each run 10 times (60 total calls to OpenAI). Every test case must include a value for each variable in the prompt template.\\\\nPrompts may have multiple variables in each test case. For example, if you want to test a prompt template that includes a variable for a comedian\\'s name and a joke topic, you can set up test cases for different comedians and topics.\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke about {subject} in the style of {comedian}\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke about {subject} in the style of {comedian}\\\\\"\\\\n\\\\n# set test cases with different input variables\\\\ncases = [\\\\n  {\\\\\"subject\\\\\": \\\\\"joe biden\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n  {\\\\\"subject\\\\\": \\\\\"joe biden\\\\\", \\\\\"comedian\\\\\": \\\\\"ricky gervais\\\\\"}, \\\\n  {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n  {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\", \\\\\"comedian\\\\\": \\\\\"ricky gervais\\\\\"}, \\\\n  ]\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], cases)\\\\nEvery case is tested against every prompt, in order to get a fair comparison of the performance of each prompt given the same input data. With 4 test cases and 2 prompts, you\\'ll get 8 combinations (4 test cases x 2 prompt templates), which will each run 10 times (80 total calls to OpenAI).\\\\nModel testing\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke\\\\\"\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], models=[\\\\\"gpt-4\\\\\", \\\\\"gpt-3.5-turbo\\\\\"])\\\\nThis will run each prompt against each model, in order to get a fair comparison of the performance of each prompt given the same input data. With 2 prompts and 2 models, you\\'ll get 4 combinations (2 prompts x 2 models), which will each run 10 times (40 total calls to OpenAI).\\\\nSystem messages\\\\n# set up a prompt templates for the a/b test\\\\nsystem_message = \\\\\"You are the comedian {comedian}\\\\\"\\\\n\\\\nprompt_a = [system_message, \\\\\"tell me a funny joke about {subject}\\\\\"]\\\\nprompt_b = [system_message, \\\\\"tell me a hillarious joke {subject}\\\\\"]\\\\n\\\\ncases = [{\\\\\"subject\\\\\": \\\\\"joe biden\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n         {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}]\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], cases)\\\\nPrompts can be a string or an array of strings. If the prompt is an array, the first string is used as a system message, and the rest of the prompts alternate between Human and Assistant messages ([system, human, ai, human, ai, ...]). This is useful for testing prompts that include a system message, or that are using pre-warming (inserting prior messages into the chat to guide the AI towards desired behavior).\\\\n# set up a prompt templates for the a/b test\\\\nsystem_message = \\\\\"You are the comedian {comedian}\\\\\"\\\\n\\\\nprompt_a = [system_message, # system\\\\n            \\\\\"tell me a funny joke about {subject}\\\\\", # human\\\\n            \\\\\"Sorry, as an AI language model, I am not capable of humor\\\\\", # assistant\\\\n            \\\\\"That\\'s fine just try your best\\\\\"] # human\\\\nprompt_b = [system_message, # system\\\\n            \\\\\"tell me a hillarious joke about {subject}\\\\\", # human\\\\n            \\\\\"Sorry, as an AI language model, I am not capable of humor\\\\\", # assistant\\\\n            \\\\\"That\\'s fine just try your best\\\\\"] # human\\\\n\\\\ncases = [{\\\\\"subject\\\\\": \\\\\"joe biden\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n         {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}]\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], cases)\\\\nEvaluation report\\\\nWhen the test completes, you get a full evaluation report, broken down by PID, CID, and model, as well as an overall report broken down by all combinations. If you only test one model or one case, these breakdowns will be dropped. The report shows a key at the bottom to see which ID corresponds to which prompt or case.\\\\n\\\\nParameters\\\\nThe thumb.test function takes the following parameters:\\\\nRequired\\\\n\\\\nprompts: an array of prompts (strings) to be tested\\\\n\\\\nOptional\\\\n\\\\ncases: a dictionary of variables to input into each prompt template (default: None)\\\\nruns: the number of responses to generate per prompt and test case (default: 10)\\\\nmodels: a list of OpenAI models you want to generate responses from (default: [gpt-3.5-turbo])\\\\nasync_generate: a boolean that denotes whether to run async or sequentially (default: True)\\\\n\\\\nIf you have 10 test runs with 2 prompt templates and 3 test cases, that\\'s 10 x 2 x 3 = 60 calls to OpenAI. Be careful: particularly with GPT-4 the costs can add up quickly!\\\\nLangchain tracing to LangSmith is automatically enabled if the LANGCHAIN_API_KEY is set as an environment variable (optional).\\\\nLoading and adding\\\\nthe .test() function returns a ThumbTest object. You can add more prompts or cases to the test, or run it additional times. You can also generate, evaluate and export the test data at any time.\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke\\\\\"\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b])\\\\n\\\\n# add more prompts\\\\ntest.add_prompts([\\\\\"tell me a knock knock joke\\\\\", \\\\\"tell me a knock knock joke about {subject}\\\\\"])\\\\n\\\\n# add more cases\\\\ntest.add_cases([{\\\\\"subject\\\\\": \\\\\"joe biden\\\\\"}, {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\"}])\\\\n\\\\n# run each prompt and case 5 more times\\\\ntest.add_runs(5)\\\\n\\\\n# generate the responses\\\\ntest.generate()\\\\n\\\\n# rate the responses\\\\ntest.evaluate()\\\\n\\\\n# export the test data for analysis\\\\ntest.export_to_csv()\\\\nEvery prompt template gets the same input data from every test case, but the prompt does not need to use all of the variables in the test case. As in the example above, the tell me a knock knock joke prompt does not use the subject variable, but it is still generated once (with no variables) for each test case.\\\\nTest data is cached in a local JSON file thumb/.cache/{TestID}.json after every set of runs is generated for a prompt and case combination.\\\\nIf your test is interrupted, or you want to add to it, you can use the thumb.load function to load the test data from the cache.\\\\n# load a previous test\\\\ntest_id = \\\\\"abcd1234\\\\\" # replace with your test id\\\\ntest = thumb.load(f\\\\\"thumb/.cache/{test_id}.json\\\\\")\\\\n\\\\n# run each prompt and case 2 more times\\\\ntest.add_runs(2)\\\\n\\\\n# generate the responses\\\\ntest.generate()\\\\n\\\\n# rate the responses\\\\ntest.evaluate()\\\\n\\\\n# export the test data for analysis\\\\ntest.export_to_csv()\\\\nEvery run for each combination of prompt and case is stored in the object (and cache), and therefore calling test.generate() again will not generate any new responses if more prompts, cases, or runs aren\\'t added. Similarly, calling test.evaluate() again will not re-rate the responses you have already rated, and will simply redisplay the results if the test has ended.\\\\nThumb Testing üëçüß™\\\\nThe difference between people just playing around with ChatGPT and those using AI in production is evaluation. LLMs respond non-deterministically, and so it\\'s important to test what results look like when scaled up across a wide range of scenarios. Without an evaluation framework you\\'re left blindly guessing about what\\'s working in your prompts (or not).\\\\nSerious prompt engineers are testing and learning which inputs lead to useful or desired outputs, reliably and at scale. This process is called prompt optimization, and it looks like this:\\\\n\\\\nMetrics ‚Äì Establish how you\\'ll measure the performance of the responses from the AI.\\\\nHypothesis ‚Äì Design one or more prompts that may work, based on the latest research.\\\\nTesting ‚Äì Generate responses for your different prompts against multiple test cases.\\\\nAnalysis ‚Äì Evaluate the performance of your prompts and use them to inform the next test.\\\\n\\\\nThumb testing fills the gap between large scale professional evaluation mechanisms, and blindly prompting through trial and error. If you are transitioning a prompt into a production environment, using thumb to test your prompt can help you catch edge cases, and get early user or team feedback on the results.\\\\nContributors\\\\nThese people are building thumb for fun in their spare time. üëç\\\\n\\\\n\\\\n\\\\n\\\\n  \\\\n    hammer-mtüíª\\\\n  \\\\n\\\\n\\\\n\\\\n\\\\n\",\"renderedFileInfo\":null,\"shortPath\":null,\"tabSize\":8,\"topBannersInfo\":{\"overridingGlobalFundingFile\":false,\"globalPreferredFundingPath\":null,\"repoOwner\":\"hammer-mt\",\"repoName\":\"thumb\",\"showInvalidCitationWarning\":false,\"citationHelpUrl\":\"https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-citation-files\",\"showDependabotConfigurationBanner\":false,\"actionsOnboardingTip\":null},\"truncated\":false,\"viewable\":true,\"workflowRedirectUrl\":null,\"symbols\":{\"timed_out\":false,\"not_analyzed\":false,\"symbols\":[{\"name\":\"thumb\",\"kind\":\"section_1\",\"ident_start\":2,\"ident_end\":7,\"extent_start\":0,\"extent_end\":11072,\"fully_qualified_name\":\"thumb\",\"ident_utf16\":{\"start\":{\"line_number\":0,\"utf16_col\":2},\"end\":{\"line_number\":0,\"utf16_col\":7}},\"extent_utf16\":{\"start\":{\"line_number\":0,\"utf16_col\":0},\"end\":{\"line_number\":249,\"utf16_col\":0}}},{\"name\":\"Quick start\",\"kind\":\"section_2\",\"ident_start\":55,\"ident_end\":66,\"extent_start\":52,\"extent_end\":1266,\"fully_qualified_name\":\"Quick start\",\"ident_utf16\":{\"start\":{\"line_number\":4,\"utf16_col\":3},\"end\":{\"line_number\":4,\"utf16_col\":14}},\"extent_utf16\":{\"start\":{\"line_number\":4,\"utf16_col\":0},\"end\":{\"line_number\":42,\"utf16_col\":0}}},{\"name\":\"1. Install the library\",\"kind\":\"section_3\",\"ident_start\":72,\"ident_end\":94,\"extent_start\":68,\"extent_end\":119,\"fully_qualified_name\":\"1. Install the library\",\"ident_utf16\":{\"start\":{\"line_number\":6,\"utf16_col\":4},\"end\":{\"line_number\":6,\"utf16_col\":26}},\"extent_utf16\":{\"start\":{\"line_number\":6,\"utf16_col\":0},\"end\":{\"line_number\":10,\"utf16_col\":0}}},{\"name\":\"2. Set up a test\",\"kind\":\"section_3\",\"ident_start\":123,\"ident_end\":139,\"extent_start\":119,\"extent_end\":480,\"fully_qualified_name\":\"2. Set up a test\",\"ident_utf16\":{\"start\":{\"line_number\":10,\"utf16_col\":4},\"end\":{\"line_number\":10,\"utf16_col\":20}},\"extent_utf16\":{\"start\":{\"line_number\":10,\"utf16_col\":0},\"end\":{\"line_number\":27,\"utf16_col\":0}}},{\"name\":\"3. Rate the responses\",\"kind\":\"section_3\",\"ident_start\":484,\"ident_end\":505,\"extent_start\":480,\"extent_end\":1266,\"fully_qualified_name\":\"3. Rate the responses\",\"ident_utf16\":{\"start\":{\"line_number\":27,\"utf16_col\":4},\"end\":{\"line_number\":27,\"utf16_col\":25}},\"extent_utf16\":{\"start\":{\"line_number\":27,\"utf16_col\":0},\"end\":{\"line_number\":42,\"utf16_col\":0}}},{\"name\":\"Functionality\",\"kind\":\"section_2\",\"ident_start\":1269,\"ident_end\":1282,\"extent_start\":1266,\"extent_end\":8932,\"fully_qualified_name\":\"Functionality\",\"ident_utf16\":{\"start\":{\"line_number\":42,\"utf16_col\":3},\"end\":{\"line_number\":42,\"utf16_col\":16}},\"extent_utf16\":{\"start\":{\"line_number\":42,\"utf16_col\":0},\"end\":{\"line_number\":218,\"utf16_col\":0}}},{\"name\":\"Test cases\",\"kind\":\"section_3\",\"ident_start\":1288,\"ident_end\":1298,\"extent_start\":1284,\"extent_end\":3348,\"fully_qualified_name\":\"Test cases\",\"ident_utf16\":{\"start\":{\"line_number\":44,\"utf16_col\":4},\"end\":{\"line_number\":44,\"utf16_col\":14}},\"extent_utf16\":{\"start\":{\"line_number\":44,\"utf16_col\":0},\"end\":{\"line_number\":87,\"utf16_col\":0}}},{\"name\":\"Model testing\",\"kind\":\"section_3\",\"ident_start\":3352,\"ident_end\":3365,\"extent_start\":3348,\"extent_end\":3878,\"fully_qualified_name\":\"Model testing\",\"ident_utf16\":{\"start\":{\"line_number\":87,\"utf16_col\":4},\"end\":{\"line_number\":87,\"utf16_col\":17}},\"extent_utf16\":{\"start\":{\"line_number\":87,\"utf16_col\":0},\"end\":{\"line_number\":100,\"utf16_col\":0}}},{\"name\":\"System messages\",\"kind\":\"section_3\",\"ident_start\":3882,\"ident_end\":3897,\"extent_start\":3878,\"extent_end\":5552,\"fully_qualified_name\":\"System messages\",\"ident_utf16\":{\"start\":{\"line_number\":100,\"utf16_col\":4},\"end\":{\"line_number\":100,\"utf16_col\":19}},\"extent_utf16\":{\"start\":{\"line_number\":100,\"utf16_col\":0},\"end\":{\"line_number\":138,\"utf16_col\":0}}},{\"name\":\"Evaluation report\",\"kind\":\"section_3\",\"ident_start\":5556,\"ident_end\":5573,\"extent_start\":5552,\"extent_end\":5924,\"fully_qualified_name\":\"Evaluation report\",\"ident_utf16\":{\"start\":{\"line_number\":138,\"utf16_col\":4},\"end\":{\"line_number\":138,\"utf16_col\":21}},\"extent_utf16\":{\"start\":{\"line_number\":138,\"utf16_col\":0},\"end\":{\"line_number\":144,\"utf16_col\":0}}},{\"name\":\"Parameters\",\"kind\":\"section_3\",\"ident_start\":5928,\"ident_end\":5938,\"extent_start\":5924,\"extent_end\":6811,\"fully_qualified_name\":\"Parameters\",\"ident_utf16\":{\"start\":{\"line_number\":144,\"utf16_col\":4},\"end\":{\"line_number\":144,\"utf16_col\":14}},\"extent_utf16\":{\"start\":{\"line_number\":144,\"utf16_col\":0},\"end\":{\"line_number\":163,\"utf16_col\":0}}},{\"name\":\"Required\",\"kind\":\"section_4\",\"ident_start\":6004,\"ident_end\":6012,\"extent_start\":5999,\"extent_end\":6073,\"fully_qualified_name\":\"Required\",\"ident_utf16\":{\"start\":{\"line_number\":148,\"utf16_col\":5},\"end\":{\"line_number\":148,\"utf16_col\":13}},\"extent_utf16\":{\"start\":{\"line_number\":148,\"utf16_col\":0},\"end\":{\"line_number\":152,\"utf16_col\":0}}},{\"name\":\"Optional\",\"kind\":\"section_4\",\"ident_start\":6078,\"ident_end\":6086,\"extent_start\":6073,\"extent_end\":6811,\"fully_qualified_name\":\"Optional\",\"ident_utf16\":{\"start\":{\"line_number\":152,\"utf16_col\":5},\"end\":{\"line_number\":152,\"utf16_col\":13}},\"extent_utf16\":{\"start\":{\"line_number\":152,\"utf16_col\":0},\"end\":{\"line_number\":163,\"utf16_col\":0}}},{\"name\":\"Loading and adding\",\"kind\":\"section_3\",\"ident_start\":6815,\"ident_end\":6833,\"extent_start\":6811,\"extent_end\":8932,\"fully_qualified_name\":\"Loading and adding\",\"ident_utf16\":{\"start\":{\"line_number\":163,\"utf16_col\":4},\"end\":{\"line_number\":163,\"utf16_col\":22}},\"extent_utf16\":{\"start\":{\"line_number\":163,\"utf16_col\":0},\"end\":{\"line_number\":218,\"utf16_col\":0}}},{\"name\":\"Thumb Testing üëçüß™\",\"kind\":\"section_2\",\"ident_start\":8935,\"ident_end\":8957,\"extent_start\":8932,\"extent_end\":10422,\"fully_qualified_name\":\"Thumb Testing üëçüß™\",\"ident_utf16\":{\"start\":{\"line_number\":218,\"utf16_col\":3},\"end\":{\"line_number\":218,\"utf16_col\":21}},\"extent_utf16\":{\"start\":{\"line_number\":218,\"utf16_col\":0},\"end\":{\"line_number\":231,\"utf16_col\":0}}},{\"name\":\"Contributors\",\"kind\":\"section_2\",\"ident_start\":10425,\"ident_end\":10437,\"extent_start\":10422,\"extent_end\":11072,\"fully_qualified_name\":\"Contributors\",\"ident_utf16\":{\"start\":{\"line_number\":231,\"utf16_col\":3},\"end\":{\"line_number\":231,\"utf16_col\":15}},\"extent_utf16\":{\"start\":{\"line_number\":231,\"utf16_col\":0},\"end\":{\"line_number\":249,\"utf16_col\":0}}}]}},\"copilotInfo\":null,\"copilotAccessAllowed\":false,\"csrf_tokens\":{\"/hammer-mt/thumb/branches\":{\"post\":\"B3-5rXBjpmpIt3mdKF2P-o0SUv9HizOxZ4OHli_twGFZyTwA4JqPUyuw0h8UkTSNWlLi7xHFP_seSTRpr5Z43A\"},\"/repos/preferences\":{\"post\":\"WPElecEkX6nWYvIaj5h74rrLyVZPzUSuK1vybrakbn3KuflDZMagSvM_lX50_PWefMHmVDBc4otvQmVieUaoKA\"}}},\"title\":\"thumb/README.md at master ¬∑ hammer-mt/thumb\"}', metadata={'source': 'README.md'})]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W_rNH3DCiYJ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "[ Document(page_content='test', metadata={'test': 'test'}) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p7rHaDryCiYK"
      },
      "outputs": [],
      "source": [
        "# Split the text into sentences:\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 300,\n",
        "    chunk_overlap  = 50,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")\n",
        "\n",
        "final_docs = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='{\"payload\":{\"allShortcutsEnabled\":false,\"fileTree\":{\"\":{\"items\":[{\"name\":\".github\",\"path\":\".github\",\"contentType\":\"directory\"},{\"name\":\"img\",\"path\":\"img\",\"contentType\":\"directory\"},{\"name\":\"notebooks\",\"path\":\"notebooks\",\"contentType\":\"directory\"},{\"name\":\"src\",\"path\":\"src\",\"contentType\":\"directory\"}', metadata={'source': 'README.md'}),\n",
              " Document(page_content='ame\":\"src\",\"path\":\"src\",\"contentType\":\"directory\"},{\"name\":\".gitignore\",\"path\":\".gitignore\",\"contentType\":\"file\"},{\"name\":\"CONTRIBUTING.md\",\"path\":\"CONTRIBUTING.md\",\"contentType\":\"file\"},{\"name\":\"README.md\",\"path\":\"README.md\",\"contentType\":\"file\"},{\"name\":\"RESOURCES.md\",\"path\":\"RESOURCES.md\",\"conten', metadata={'source': 'README.md'}),\n",
              " Document(page_content='name\":\"RESOURCES.md\",\"path\":\"RESOURCES.md\",\"contentType\":\"file\"},{\"name\":\"TODO.md\",\"path\":\"TODO.md\",\"contentType\":\"file\"},{\"name\":\"requirements.txt\",\"path\":\"requirements.txt\",\"contentType\":\"file\"},{\"name\":\"setup.py\",\"path\":\"setup.py\",\"contentType\":\"file\"},{\"name\":\"webui.bat\",\"path\":\"webui.bat\",\"cont', metadata={'source': 'README.md'}),\n",
              " Document(page_content='ile\"},{\"name\":\"webui.bat\",\"path\":\"webui.bat\",\"contentType\":\"file\"},{\"name\":\"webui.sh\",\"path\":\"webui.sh\",\"contentType\":\"file\"}],\"totalCount\":13}},\"fileTreeProcessingTime\":5.820067,\"foldersToFetch\":[],\"reducedMotionEnabled\":null,\"repo\":{\"id\":684171643,\"defaultBranch\":\"master\",\"name\":\"thumb\",\"ownerLogi', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\"defaultBranch\":\"master\",\"name\":\"thumb\",\"ownerLogin\":\"hammer-mt\",\"currentUserCanPush\":false,\"isFork\":false,\"isEmpty\":false,\"createdAt\":\"2023-08-28T15:48:03.000Z\",\"ownerAvatar\":\"https://avatars.githubusercontent.com/u/5264596?v=4\",\"public\":true,\"private\":false,\"isOrgOwned\":false},\"symbolsExpanded\":fa', metadata={'source': 'README.md'}),\n",
              " Document(page_content='te\":false,\"isOrgOwned\":false},\"symbolsExpanded\":false,\"treeExpanded\":true,\"refInfo\":{\"name\":\"master\",\"listCacheKey\":\"v0:1702391649.0\",\"canEdit\":false,\"refType\":\"branch\",\"currentOid\":\"8a3d39895b998991c3fc3b95c7cc2bf2a5642f85\"},\"path\":\"README.md\",\"currentUser\":null,\"blob\":{\"rawLines\":null,\"stylingDire', metadata={'source': 'README.md'}),\n",
              " Document(page_content='entUser\":null,\"blob\":{\"rawLines\":null,\"stylingDirectives\":null,\"csv\":null,\"csvError\":null,\"dependabotInfo\":{\"showConfigurationBanner\":false,\"configFilePath\":null,\"networkDependabotPath\":\"/hammer-mt/thumb/network/updates\",\"dismissConfigurationNoticePath\":\"/settings/dismiss-notice/dependabot_configura', metadata={'source': 'README.md'}),\n",
              " Document(page_content='th\":\"/settings/dismiss-notice/dependabot_configuration_notice\",\"configurationNoticeDismissed\":null,\"repoAlertsPath\":\"/hammer-mt/thumb/security/dependabot\",\"repoSecurityAndAnalysisPath\":\"/hammer-mt/thumb/settings/security_analysis\",\"repoOwnerIsOrg\":false,\"currentUserCanAdminRepo\":false},\"displayName\"', metadata={'source': 'README.md'}),\n",
              " Document(page_content='lse,\"currentUserCanAdminRepo\":false},\"displayName\":\"README.md\",\"displayUrl\":\"https://github.com/hammer-mt/thumb/blob/master/README.md?raw=true\",\"headerInfo\":{\"blobSize\":\"10.8', metadata={'source': 'README.md'}),\n",
              " Document(page_content='KB\",\"deleteInfo\":{\"deleteTooltip\":\"You must be signed in to make or propose changes\"},\"editInfo\":{\"editTooltip\":\"You must be signed in to make or propose', metadata={'source': 'README.md'}),\n",
              " Document(page_content='changes\"},\"ghDesktopPath\":\"https://desktop.github.com\",\"gitLfsPath\":null,\"onBranch\":true,\"shortPath\":\"054a9b9\",\"siteNavLoginPath\":\"/login?return_to=https%3A%2F%2Fgithub.com%2Fhammer-mt%2Fthumb%2Fblob%2Fmaster%2FREADME.md\",\"isCSV\":false,\"isRichtext\":true,\"toc\":[{\"level\":1,\"text\":\"thumb\",\"anchor\":\"th', metadata={'source': 'README.md'}),\n",
              " Document(page_content='true,\"toc\":[{\"level\":1,\"text\":\"thumb\",\"anchor\":\"thumb\",\"htmlText\":\"thumb\"},{\"level\":2,\"text\":\"Quick', metadata={'source': 'README.md'}),\n",
              " Document(page_content='start\",\"anchor\":\"quick-start\",\"htmlText\":\"Quick start\"},{\"level\":3,\"text\":\"1. Install the library\",\"anchor\":\"1-install-the-library\",\"htmlText\":\"1. Install the library\"},{\"level\":3,\"text\":\"2. Set up a test\",\"anchor\":\"2-set-up-a-test\",\"htmlText\":\"2. Set up a test\"},{\"level\":3,\"text\":\"3. Rate the', metadata={'source': 'README.md'}),\n",
              " Document(page_content='Set up a test\"},{\"level\":3,\"text\":\"3. Rate the responses\",\"anchor\":\"3-rate-the-responses\",\"htmlText\":\"3. Rate the responses\"},{\"level\":2,\"text\":\"Functionality\",\"anchor\":\"functionality\",\"htmlText\":\"Functionality\"},{\"level\":3,\"text\":\"Test cases\",\"anchor\":\"test-cases\",\"htmlText\":\"Test', metadata={'source': 'README.md'}),\n",
              " Document(page_content='cases\",\"anchor\":\"test-cases\",\"htmlText\":\"Test cases\"},{\"level\":3,\"text\":\"Model testing\",\"anchor\":\"model-testing\",\"htmlText\":\"Model testing\"},{\"level\":3,\"text\":\"System messages\",\"anchor\":\"system-messages\",\"htmlText\":\"System messages\"},{\"level\":3,\"text\":\"Evaluation', metadata={'source': 'README.md'}),\n",
              " Document(page_content='messages\"},{\"level\":3,\"text\":\"Evaluation report\",\"anchor\":\"evaluation-report\",\"htmlText\":\"Evaluation', metadata={'source': 'README.md'}),\n",
              " Document(page_content='report\"},{\"level\":3,\"text\":\"Parameters\",\"anchor\":\"parameters\",\"htmlText\":\"Parameters\"},{\"level\":4,\"text\":\"Required\",\"anchor\":\"required\",\"htmlText\":\"Required\"},{\"level\":4,\"text\":\"Optional\",\"anchor\":\"optional\",\"htmlText\":\"Optional\"},{\"level\":3,\"text\":\"Loading and', metadata={'source': 'README.md'}),\n",
              " Document(page_content='and adding\",\"anchor\":\"loading-and-adding\",\"htmlText\":\"Loading and adding\"},{\"level\":2,\"text\":\"Thumb Testing üëçüß™\",\"anchor\":\"thumb-testing-\",\"htmlText\":\"Thumb Testing', metadata={'source': 'README.md'}),\n",
              " Document(page_content='üëçüß™\"},{\"level\":2,\"text\":\"Contributors\",\"anchor\":\"contributors\",\"htmlText\":\"Contributors\"}],\"lineInfo\":{\"truncatedLoc\":\"249\",\"truncatedSloc\":\"169\"},\"mode\":\"file\"},\"image\":false,\"isCodeownersFile\":null,\"isPlain\":false,\"isValidLegacyIssueTemplate\":false,\"issueTemplateHelpUrl\":\"https://docs.github.com/a', metadata={'source': 'README.md'}),\n",
              " Document(page_content=',\"issueTemplateHelpUrl\":\"https://docs.github.com/articles/about-issue-and-pull-request-templates\",\"issueTemplate\":null,\"discussionTemplate\":null,\"language\":\"Markdown\",\"languageID\":222,\"large\":false,\"loggedIn\":false,\"newDiscussionPath\":\"/hammer-mt/thumb/discussions/new\",\"newIssuePath\":\"/hammer-mt/thu', metadata={'source': 'README.md'}),\n",
              " Document(page_content='mb/discussions/new\",\"newIssuePath\":\"/hammer-mt/thumb/issues/new\",\"planSupportInfo\":{\"repoIsFork\":null,\"repoOwnedByCurrentUser\":null,\"requestFullPath\":\"/hammer-mt/thumb/blob/master/README.md\",\"showFreeOrgGatedFeatureMessage\":null,\"showPlanSupportBanner\":null,\"upgradeDataAttributes\":null,\"upgradePath\"', metadata={'source': 'README.md'}),\n",
              " Document(page_content='r\":null,\"upgradeDataAttributes\":null,\"upgradePath\":null},\"publishBannersInfo\":{\"dismissActionNoticePath\":\"/settings/dismiss-notice/publish_action_from_dockerfile\",\"dismissStackNoticePath\":\"/settings/dismiss-notice/publish_stack_from_file\",\"releasePath\":\"/hammer-mt/thumb/releases/new?marketplace=true', metadata={'source': 'README.md'}),\n",
              " Document(page_content='h\":\"/hammer-mt/thumb/releases/new?marketplace=true\",\"showPublishActionBanner\":false,\"showPublishStackBanner\":false},\"rawBlobUrl\":\"https://github.com/hammer-mt/thumb/raw/master/README.md\",\"renderImageOrRaw\":false,\"richText\":\"thumb\\\\nA', metadata={'source': 'README.md'}),\n",
              " Document(page_content='simple prompt testing library for LLMs.\\\\nQuick start\\\\n1. Install the library\\\\n\\\\npip install thumb\\\\n\\\\n2. Set up a test\\\\nimport os\\\\nimport thumb\\\\n\\\\n# Set your API key: https://platform.openai.com/account/api-keys\\\\nos.environ[\\\\\"OPENAI_API_KEY\\\\\"] = \\\\\"YOUR_API_KEY_HERE\\\\\"\\\\n\\\\n# set up a prompt templates', metadata={'source': 'README.md'}),\n",
              " Document(page_content='set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke\\\\\"\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b])\\\\n3. Rate the responses\\\\nEach prompt is run 10 times asynchronously by default, which is around 9x faster than', metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"by default, which is around 9x faster than running them sequentially. In Jupyter Notebooks a simple user interface is displayed for blind rating responses (you don't see which prompt generated the response).\\\\n\\\\nOnce all responses have been rated, the following performance statistics are calculated\", metadata={'source': 'README.md'}),\n",
              " Document(page_content='following performance statistics are calculated broken down by prompt template:\\\\n\\\\navg_score amount of positive feedback as a percentage of all runs\\\\navg_tokens: how many tokens were used across the prompt and response\\\\navg_cost: an estimate of how much the prompt cost to run on average\\\\n\\\\nA simple', metadata={'source': 'README.md'}),\n",
              " Document(page_content='the prompt cost to run on average\\\\n\\\\nA simple report is displayed in the notebook, and the full data is saved to a CSV file thumb/ThumbTest-{TestID}.csv.\\\\n\\\\nFunctionality\\\\nTest cases\\\\nTest cases are when you want to test a prompt template with different input variables. For example, if you want to', metadata={'source': 'README.md'}),\n",
              " Document(page_content='input variables. For example, if you want to test a prompt template that includes a variable for a comedian\\'s name, you can set up test cases for different comedians.\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke in the style of {comedian}\\\\\"\\\\nprompt_b = \\\\\"tell me a', metadata={'source': 'README.md'}),\n",
              " Document(page_content='the style of {comedian}\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke in the style of {comedian}\\\\\"\\\\n\\\\n# set test cases with different input variables\\\\ncases = [\\\\n  {\\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n  {\\\\\"comedian\\\\\": \\\\\"ricky gervais\\\\\"}, \\\\n  {\\\\\"comedian\\\\\": \\\\\"robin williams\\\\\"}\\\\n  ]\\\\n\\\\n# generate the', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\\\\\"robin williams\\\\\"}\\\\n  ]\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], cases)\\\\nEvery test case will be run against every prompt template, so in this example you\\'ll get 6 combinations (3 test cases x 2 prompt templates), which will each run 10 times (60 total calls to OpenAI).', metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"each run 10 times (60 total calls to OpenAI). Every test case must include a value for each variable in the prompt template.\\\\nPrompts may have multiple variables in each test case. For example, if you want to test a prompt template that includes a variable for a comedian's name and a joke topic,\", metadata={'source': 'README.md'}),\n",
              " Document(page_content='variable for a comedian\\'s name and a joke topic, you can set up test cases for different comedians and topics.\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke about {subject} in the style of {comedian}\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke about {subject} in the', metadata={'source': 'README.md'}),\n",
              " Document(page_content='me a family friendly joke about {subject} in the style of {comedian}\\\\\"\\\\n\\\\n# set test cases with different input variables\\\\ncases = [\\\\n  {\\\\\"subject\\\\\": \\\\\"joe biden\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n  {\\\\\"subject\\\\\": \\\\\"joe biden\\\\\", \\\\\"comedian\\\\\": \\\\\"ricky gervais\\\\\"}, \\\\n  {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\",', metadata={'source': 'README.md'}),\n",
              " Document(page_content='gervais\\\\\"}, \\\\n  {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n  {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\", \\\\\"comedian\\\\\": \\\\\"ricky gervais\\\\\"}, \\\\n  ]\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], cases)\\\\nEvery case is tested against every prompt, in order to get a fair', metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"against every prompt, in order to get a fair comparison of the performance of each prompt given the same input data. With 4 test cases and 2 prompts, you'll get 8 combinations (4 test cases x 2 prompt templates), which will each run 10 times (80 total calls to OpenAI).\\\\nModel testing\\\\n# set up a\", metadata={'source': 'README.md'}),\n",
              " Document(page_content='calls to OpenAI).\\\\nModel testing\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke\\\\\"\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], models=[\\\\\"gpt-4\\\\\", \\\\\"gpt-3.5-turbo\\\\\"])\\\\nThis will run each prompt against', metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"will run each prompt against each model, in order to get a fair comparison of the performance of each prompt given the same input data. With 2 prompts and 2 models, you'll get 4 combinations (2 prompts x 2 models), which will each run 10 times (40 total calls to OpenAI).\\\\nSystem messages\\\\n# set up\", metadata={'source': 'README.md'}),\n",
              " Document(page_content='calls to OpenAI).\\\\nSystem messages\\\\n# set up a prompt templates for the a/b test\\\\nsystem_message = \\\\\"You are the comedian {comedian}\\\\\"\\\\n\\\\nprompt_a = [system_message, \\\\\"tell me a funny joke about {subject}\\\\\"]\\\\nprompt_b = [system_message, \\\\\"tell me a hillarious joke {subject}\\\\\"]\\\\n\\\\ncases =', metadata={'source': 'README.md'}),\n",
              " Document(page_content='me a hillarious joke {subject}\\\\\"]\\\\n\\\\ncases = [{\\\\\"subject\\\\\": \\\\\"joe biden\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n         {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}]\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], cases)\\\\nPrompts can be a string or an array of', metadata={'source': 'README.md'}),\n",
              " Document(page_content='cases)\\\\nPrompts can be a string or an array of strings. If the prompt is an array, the first string is used as a system message, and the rest of the prompts alternate between Human and Assistant messages ([system, human, ai, human, ai, ...]). This is useful for testing prompts that include a system', metadata={'source': 'README.md'}),\n",
              " Document(page_content='useful for testing prompts that include a system message, or that are using pre-warming (inserting prior messages into the chat to guide the AI towards desired behavior).\\\\n# set up a prompt templates for the a/b test\\\\nsystem_message = \\\\\"You are the comedian {comedian}\\\\\"\\\\n\\\\nprompt_a =', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\\\\\"You are the comedian {comedian}\\\\\"\\\\n\\\\nprompt_a = [system_message, # system\\\\n            \\\\\"tell me a funny joke about {subject}\\\\\", # human\\\\n            \\\\\"Sorry, as an AI language model, I am not capable of humor\\\\\", # assistant\\\\n            \\\\\"That\\'s fine just try your best\\\\\"] # human\\\\nprompt_b =', metadata={'source': 'README.md'}),\n",
              " Document(page_content='fine just try your best\\\\\"] # human\\\\nprompt_b = [system_message, # system\\\\n            \\\\\"tell me a hillarious joke about {subject}\\\\\", # human\\\\n            \\\\\"Sorry, as an AI language model, I am not capable of humor\\\\\", # assistant\\\\n            \\\\\"That\\'s fine just try your best\\\\\"] # human\\\\n\\\\ncases =', metadata={'source': 'README.md'}),\n",
              " Document(page_content='fine just try your best\\\\\"] # human\\\\n\\\\ncases = [{\\\\\"subject\\\\\": \\\\\"joe biden\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}, \\\\n         {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\", \\\\\"comedian\\\\\": \\\\\"chris rock\\\\\"}]\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a, prompt_b], cases)\\\\nEvaluation report\\\\nWhen the test', metadata={'source': 'README.md'}),\n",
              " Document(page_content='cases)\\\\nEvaluation report\\\\nWhen the test completes, you get a full evaluation report, broken down by PID, CID, and model, as well as an overall report broken down by all combinations. If you only test one model or one case, these breakdowns will be dropped. The report shows a key at the bottom to', metadata={'source': 'README.md'}),\n",
              " Document(page_content='dropped. The report shows a key at the bottom to see which ID corresponds to which prompt or case.\\\\n\\\\nParameters\\\\nThe thumb.test function takes the following parameters:\\\\nRequired\\\\n\\\\nprompts: an array of prompts (strings) to be tested\\\\n\\\\nOptional\\\\n\\\\ncases: a dictionary of variables to input into', metadata={'source': 'README.md'}),\n",
              " Document(page_content='a dictionary of variables to input into each prompt template (default: None)\\\\nruns: the number of responses to generate per prompt and test case (default: 10)\\\\nmodels: a list of OpenAI models you want to generate responses from (default: [gpt-3.5-turbo])\\\\nasync_generate: a boolean that denotes', metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"a boolean that denotes whether to run async or sequentially (default: True)\\\\n\\\\nIf you have 10 test runs with 2 prompt templates and 3 test cases, that's 10 x 2 x 3 = 60 calls to OpenAI. Be careful: particularly with GPT-4 the costs can add up quickly!\\\\nLangchain tracing to LangSmith is\", metadata={'source': 'README.md'}),\n",
              " Document(page_content='up quickly!\\\\nLangchain tracing to LangSmith is automatically enabled if the LANGCHAIN_API_KEY is set as an environment variable (optional).\\\\nLoading and adding\\\\nthe .test() function returns a ThumbTest object. You can add more prompts or cases to the test, or run it additional times. You can also', metadata={'source': 'README.md'}),\n",
              " Document(page_content='test, or run it additional times. You can also generate, evaluate and export the test data at any time.\\\\n# set up a prompt templates for the a/b test\\\\nprompt_a = \\\\\"tell me a joke\\\\\"\\\\nprompt_b = \\\\\"tell me a family friendly joke\\\\\"\\\\n\\\\n# generate the responses\\\\ntest = thumb.test([prompt_a,', metadata={'source': 'README.md'}),\n",
              " Document(page_content='the responses\\\\ntest = thumb.test([prompt_a, prompt_b])\\\\n\\\\n# add more prompts\\\\ntest.add_prompts([\\\\\"tell me a knock knock joke\\\\\", \\\\\"tell me a knock knock joke about {subject}\\\\\"])\\\\n\\\\n# add more cases\\\\ntest.add_cases([{\\\\\"subject\\\\\": \\\\\"joe biden\\\\\"}, {\\\\\"subject\\\\\": \\\\\"donald trump\\\\\"}])\\\\n\\\\n# run each prompt', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\\\\\"donald trump\\\\\"}])\\\\n\\\\n# run each prompt and case 5 more times\\\\ntest.add_runs(5)\\\\n\\\\n# generate the responses\\\\ntest.generate()\\\\n\\\\n# rate the responses\\\\ntest.evaluate()\\\\n\\\\n# export the test data for analysis\\\\ntest.export_to_csv()\\\\nEvery prompt template gets the same input data from every test case,', metadata={'source': 'README.md'}),\n",
              " Document(page_content='gets the same input data from every test case, but the prompt does not need to use all of the variables in the test case. As in the example above, the tell me a knock knock joke prompt does not use the subject variable, but it is still generated once (with no variables) for each test case.\\\\nTest', metadata={'source': 'README.md'}),\n",
              " Document(page_content='(with no variables) for each test case.\\\\nTest data is cached in a local JSON file thumb/.cache/{TestID}.json after every set of runs is generated for a prompt and case combination.\\\\nIf your test is interrupted, or you want to add to it, you can use the thumb.load function to load the test data from', metadata={'source': 'README.md'}),\n",
              " Document(page_content='thumb.load function to load the test data from the cache.\\\\n# load a previous test\\\\ntest_id = \\\\\"abcd1234\\\\\" # replace with your test id\\\\ntest = thumb.load(f\\\\\"thumb/.cache/{test_id}.json\\\\\")\\\\n\\\\n# run each prompt and case 2 more times\\\\ntest.add_runs(2)\\\\n\\\\n# generate the responses\\\\ntest.generate()\\\\n\\\\n#', metadata={'source': 'README.md'}),\n",
              " Document(page_content='generate the responses\\\\ntest.generate()\\\\n\\\\n# rate the responses\\\\ntest.evaluate()\\\\n\\\\n# export the test data for analysis\\\\ntest.export_to_csv()\\\\nEvery run for each combination of prompt and case is stored in the object (and cache), and therefore calling test.generate() again will not generate any new', metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"test.generate() again will not generate any new responses if more prompts, cases, or runs aren't added. Similarly, calling test.evaluate() again will not re-rate the responses you have already rated, and will simply redisplay the results if the test has ended.\\\\nThumb Testing üëçüß™\\\\nThe difference\", metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"test has ended.\\\\nThumb Testing üëçüß™\\\\nThe difference between people just playing around with ChatGPT and those using AI in production is evaluation. LLMs respond non-deterministically, and so it's important to test what results look like when scaled up across a wide range of scenarios. Without an\", metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"up across a wide range of scenarios. Without an evaluation framework you're left blindly guessing about what's working in your prompts (or not).\\\\nSerious prompt engineers are testing and learning which inputs lead to useful or desired outputs, reliably and at scale. This process is called prompt\", metadata={'source': 'README.md'}),\n",
              " Document(page_content=\"and at scale. This process is called prompt optimization, and it looks like this:\\\\n\\\\nMetrics ‚Äì Establish how you'll measure the performance of the responses from the AI.\\\\nHypothesis ‚Äì Design one or more prompts that may work, based on the latest research.\\\\nTesting ‚Äì Generate responses for your\", metadata={'source': 'README.md'}),\n",
              " Document(page_content='research.\\\\nTesting ‚Äì Generate responses for your different prompts against multiple test cases.\\\\nAnalysis ‚Äì Evaluate the performance of your prompts and use them to inform the next test.\\\\n\\\\nThumb testing fills the gap between large scale professional evaluation mechanisms, and blindly prompting', metadata={'source': 'README.md'}),\n",
              " Document(page_content='evaluation mechanisms, and blindly prompting through trial and error. If you are transitioning a prompt into a production environment, using thumb to test your prompt can help you catch edge cases, and get early user or team feedback on the results.\\\\nContributors\\\\nThese people are building thumb', metadata={'source': 'README.md'}),\n",
              " Document(page_content='people are building thumb for fun in their spare time. üëç\\\\n\\\\n\\\\n\\\\n\\\\n  \\\\n    hammer-mtüíª\\\\n', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\\\\n\\\\n\\\\n\\\\n\\\\n\",\"renderedFileInfo\":null,\"shortPath\":null,\"tabSize\":8,\"topBannersInfo\":{\"overridingGlobalFundingFile\":false,\"globalPreferredFundingPath\":null,\"repoOwner\":\"hammer-mt\",\"repoName\":\"thumb\",\"showInvalidCitationWarning\":false,\"citationHelpUrl\":\"https://docs.github.com/en/github/creating-clonin', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\"https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-citation-files\",\"showDependabotConfigurationBanner\":false,\"actionsOnboardingTip\":null},\"truncated\":false,\"viewable\":true,\"workflowRedirectUrl\":null,\"symbols\":{\"timed_out\":false,\"not_a', metadata={'source': 'README.md'}),\n",
              " Document(page_content='irectUrl\":null,\"symbols\":{\"timed_out\":false,\"not_analyzed\":false,\"symbols\":[{\"name\":\"thumb\",\"kind\":\"section_1\",\"ident_start\":2,\"ident_end\":7,\"extent_start\":0,\"extent_end\":11072,\"fully_qualified_name\":\"thumb\",\"ident_utf16\":{\"start\":{\"line_number\":0,\"utf16_col\":2},\"end\":{\"line_number\":0,\"utf16_col\":7}', metadata={'source': 'README.md'}),\n",
              " Document(page_content='tf16_col\":2},\"end\":{\"line_number\":0,\"utf16_col\":7}},\"extent_utf16\":{\"start\":{\"line_number\":0,\"utf16_col\":0},\"end\":{\"line_number\":249,\"utf16_col\":0}}},{\"name\":\"Quick', metadata={'source': 'README.md'}),\n",
              " Document(page_content='start\",\"kind\":\"section_2\",\"ident_start\":55,\"ident_end\":66,\"extent_start\":52,\"extent_end\":1266,\"fully_qualified_name\":\"Quick', metadata={'source': 'README.md'}),\n",
              " Document(page_content='start\",\"ident_utf16\":{\"start\":{\"line_number\":4,\"utf16_col\":3},\"end\":{\"line_number\":4,\"utf16_col\":14}},\"extent_utf16\":{\"start\":{\"line_number\":4,\"utf16_col\":0},\"end\":{\"line_number\":42,\"utf16_col\":0}}},{\"name\":\"1. Install the', metadata={'source': 'README.md'}),\n",
              " Document(page_content='Install the library\",\"kind\":\"section_3\",\"ident_start\":72,\"ident_end\":94,\"extent_start\":68,\"extent_end\":119,\"fully_qualified_name\":\"1. Install the', metadata={'source': 'README.md'}),\n",
              " Document(page_content='Install the library\",\"ident_utf16\":{\"start\":{\"line_number\":6,\"utf16_col\":4},\"end\":{\"line_number\":6,\"utf16_col\":26}},\"extent_utf16\":{\"start\":{\"line_number\":6,\"utf16_col\":0},\"end\":{\"line_number\":10,\"utf16_col\":0}}},{\"name\":\"2. Set up a', metadata={'source': 'README.md'}),\n",
              " Document(page_content='Set up a test\",\"kind\":\"section_3\",\"ident_start\":123,\"ident_end\":139,\"extent_start\":119,\"extent_end\":480,\"fully_qualified_name\":\"2. Set up a', metadata={'source': 'README.md'}),\n",
              " Document(page_content='Set up a test\",\"ident_utf16\":{\"start\":{\"line_number\":10,\"utf16_col\":4},\"end\":{\"line_number\":10,\"utf16_col\":20}},\"extent_utf16\":{\"start\":{\"line_number\":10,\"utf16_col\":0},\"end\":{\"line_number\":27,\"utf16_col\":0}}},{\"name\":\"3. Rate the', metadata={'source': 'README.md'}),\n",
              " Document(page_content='Rate the responses\",\"kind\":\"section_3\",\"ident_start\":484,\"ident_end\":505,\"extent_start\":480,\"extent_end\":1266,\"fully_qualified_name\":\"3. Rate the', metadata={'source': 'README.md'}),\n",
              " Document(page_content='responses\",\"ident_utf16\":{\"start\":{\"line_number\":27,\"utf16_col\":4},\"end\":{\"line_number\":27,\"utf16_col\":25}},\"extent_utf16\":{\"start\":{\"line_number\":27,\"utf16_col\":0},\"end\":{\"line_number\":42,\"utf16_col\":0}}},{\"name\":\"Functionality\",\"kind\":\"section_2\",\"ident_start\":1269,\"ident_end\":1282,\"extent_start\"', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\"ident_start\":1269,\"ident_end\":1282,\"extent_start\":1266,\"extent_end\":8932,\"fully_qualified_name\":\"Functionality\",\"ident_utf16\":{\"start\":{\"line_number\":42,\"utf16_col\":3},\"end\":{\"line_number\":42,\"utf16_col\":16}},\"extent_utf16\":{\"start\":{\"line_number\":42,\"utf16_col\":0},\"end\":{\"line_number\":218,\"utf16_c', metadata={'source': 'README.md'}),\n",
              " Document(page_content='2,\"utf16_col\":0},\"end\":{\"line_number\":218,\"utf16_col\":0}}},{\"name\":\"Test', metadata={'source': 'README.md'}),\n",
              " Document(page_content='cases\",\"kind\":\"section_3\",\"ident_start\":1288,\"ident_end\":1298,\"extent_start\":1284,\"extent_end\":3348,\"fully_qualified_name\":\"Test', metadata={'source': 'README.md'}),\n",
              " Document(page_content='cases\",\"ident_utf16\":{\"start\":{\"line_number\":44,\"utf16_col\":4},\"end\":{\"line_number\":44,\"utf16_col\":14}},\"extent_utf16\":{\"start\":{\"line_number\":44,\"utf16_col\":0},\"end\":{\"line_number\":87,\"utf16_col\":0}}},{\"name\":\"Model', metadata={'source': 'README.md'}),\n",
              " Document(page_content='testing\",\"kind\":\"section_3\",\"ident_start\":3352,\"ident_end\":3365,\"extent_start\":3348,\"extent_end\":3878,\"fully_qualified_name\":\"Model', metadata={'source': 'README.md'}),\n",
              " Document(page_content='testing\",\"ident_utf16\":{\"start\":{\"line_number\":87,\"utf16_col\":4},\"end\":{\"line_number\":87,\"utf16_col\":17}},\"extent_utf16\":{\"start\":{\"line_number\":87,\"utf16_col\":0},\"end\":{\"line_number\":100,\"utf16_col\":0}}},{\"name\":\"System', metadata={'source': 'README.md'}),\n",
              " Document(page_content='messages\",\"kind\":\"section_3\",\"ident_start\":3882,\"ident_end\":3897,\"extent_start\":3878,\"extent_end\":5552,\"fully_qualified_name\":\"System', metadata={'source': 'README.md'}),\n",
              " Document(page_content='messages\",\"ident_utf16\":{\"start\":{\"line_number\":100,\"utf16_col\":4},\"end\":{\"line_number\":100,\"utf16_col\":19}},\"extent_utf16\":{\"start\":{\"line_number\":100,\"utf16_col\":0},\"end\":{\"line_number\":138,\"utf16_col\":0}}},{\"name\":\"Evaluation', metadata={'source': 'README.md'}),\n",
              " Document(page_content='report\",\"kind\":\"section_3\",\"ident_start\":5556,\"ident_end\":5573,\"extent_start\":5552,\"extent_end\":5924,\"fully_qualified_name\":\"Evaluation', metadata={'source': 'README.md'}),\n",
              " Document(page_content='report\",\"ident_utf16\":{\"start\":{\"line_number\":138,\"utf16_col\":4},\"end\":{\"line_number\":138,\"utf16_col\":21}},\"extent_utf16\":{\"start\":{\"line_number\":138,\"utf16_col\":0},\"end\":{\"line_number\":144,\"utf16_col\":0}}},{\"name\":\"Parameters\",\"kind\":\"section_3\",\"ident_start\":5928,\"ident_end\":5938,\"extent_start\":5', metadata={'source': 'README.md'}),\n",
              " Document(page_content='dent_start\":5928,\"ident_end\":5938,\"extent_start\":5924,\"extent_end\":6811,\"fully_qualified_name\":\"Parameters\",\"ident_utf16\":{\"start\":{\"line_number\":144,\"utf16_col\":4},\"end\":{\"line_number\":144,\"utf16_col\":14}},\"extent_utf16\":{\"start\":{\"line_number\":144,\"utf16_col\":0},\"end\":{\"line_number\":163,\"utf16_col', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\"utf16_col\":0},\"end\":{\"line_number\":163,\"utf16_col\":0}}},{\"name\":\"Required\",\"kind\":\"section_4\",\"ident_start\":6004,\"ident_end\":6012,\"extent_start\":5999,\"extent_end\":6073,\"fully_qualified_name\":\"Required\",\"ident_utf16\":{\"start\":{\"line_number\":148,\"utf16_col\":5},\"end\":{\"line_number\":148,\"utf16_col\":13}', metadata={'source': 'README.md'}),\n",
              " Document(page_content='6_col\":5},\"end\":{\"line_number\":148,\"utf16_col\":13}},\"extent_utf16\":{\"start\":{\"line_number\":148,\"utf16_col\":0},\"end\":{\"line_number\":152,\"utf16_col\":0}}},{\"name\":\"Optional\",\"kind\":\"section_4\",\"ident_start\":6078,\"ident_end\":6086,\"extent_start\":6073,\"extent_end\":6811,\"fully_qualified_name\":\"Optional\",\"i', metadata={'source': 'README.md'}),\n",
              " Document(page_content='ent_end\":6811,\"fully_qualified_name\":\"Optional\",\"ident_utf16\":{\"start\":{\"line_number\":152,\"utf16_col\":5},\"end\":{\"line_number\":152,\"utf16_col\":13}},\"extent_utf16\":{\"start\":{\"line_number\":152,\"utf16_col\":0},\"end\":{\"line_number\":163,\"utf16_col\":0}}},{\"name\":\"Loading', metadata={'source': 'README.md'}),\n",
              " Document(page_content='and adding\",\"kind\":\"section_3\",\"ident_start\":6815,\"ident_end\":6833,\"extent_start\":6811,\"extent_end\":8932,\"fully_qualified_name\":\"Loading and', metadata={'source': 'README.md'}),\n",
              " Document(page_content='and adding\",\"ident_utf16\":{\"start\":{\"line_number\":163,\"utf16_col\":4},\"end\":{\"line_number\":163,\"utf16_col\":22}},\"extent_utf16\":{\"start\":{\"line_number\":163,\"utf16_col\":0},\"end\":{\"line_number\":218,\"utf16_col\":0}}},{\"name\":\"Thumb Testing', metadata={'source': 'README.md'}),\n",
              " Document(page_content='Testing üëçüß™\",\"kind\":\"section_2\",\"ident_start\":8935,\"ident_end\":8957,\"extent_start\":8932,\"extent_end\":10422,\"fully_qualified_name\":\"Thumb Testing', metadata={'source': 'README.md'}),\n",
              " Document(page_content='üëçüß™\",\"ident_utf16\":{\"start\":{\"line_number\":218,\"utf16_col\":3},\"end\":{\"line_number\":218,\"utf16_col\":21}},\"extent_utf16\":{\"start\":{\"line_number\":218,\"utf16_col\":0},\"end\":{\"line_number\":231,\"utf16_col\":0}}},{\"name\":\"Contributors\",\"kind\":\"section_2\",\"ident_start\":10425,\"ident_end\":10437,\"extent_start\":1', metadata={'source': 'README.md'}),\n",
              " Document(page_content='nt_start\":10425,\"ident_end\":10437,\"extent_start\":10422,\"extent_end\":11072,\"fully_qualified_name\":\"Contributors\",\"ident_utf16\":{\"start\":{\"line_number\":231,\"utf16_col\":3},\"end\":{\"line_number\":231,\"utf16_col\":15}},\"extent_utf16\":{\"start\":{\"line_number\":231,\"utf16_col\":0},\"end\":{\"line_number\":249,\"utf16', metadata={'source': 'README.md'}),\n",
              " Document(page_content='231,\"utf16_col\":0},\"end\":{\"line_number\":249,\"utf16_col\":0}}}]}},\"copilotInfo\":null,\"copilotAccessAllowed\":false,\"csrf_tokens\":{\"/hammer-mt/thumb/branches\":{\"post\":\"B3-5rXBjpmpIt3mdKF2P-o0SUv9HizOxZ4OHli_twGFZyTwA4JqPUyuw0h8UkTSNWlLi7xHFP_seSTRpr5Z43A\"},\"/repos/preferences\":{\"post\":\"WPElecEkX6nWYvIaj', metadata={'source': 'README.md'}),\n",
              " Document(page_content='\"},\"/repos/preferences\":{\"post\":\"WPElecEkX6nWYvIaj5h74rrLyVZPzUSuK1vybrakbn3KuflDZMagSvM_lX50_PWefMHmVDBc4otvQmVieUaoKA\"}}},\"title\":\"thumb/README.md', metadata={'source': 'README.md'}),\n",
              " Document(page_content='at master ¬∑ hammer-mt/thumb\"}', metadata={'source': 'README.md'})]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EVpwwheFCiYK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(final_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XJt0jvzqCiYK"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "chat = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PRqOsYmgCiYK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rgri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The text contains various pieces of information, but without more context, it is difficult to provide a specific summary.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = load_summarize_chain(llm=chat, chain_type=\"map_reduce\")\n",
        "chain.run({\n",
        "    \"input_documents\": final_docs,\n",
        "})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
